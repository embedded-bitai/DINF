{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [20/Oct/2020 17:26:55] \"\u001b[37mGET /Flask_Test HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/Flask_Test')\n",
    "def hello_world():\n",
    "    return 'Hello World!'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "\n",
    "# feature extractoring and preprocessing data\n",
    "# 음원 데이터를 분석\n",
    "import librosa\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것\n",
    "%matplotlib inline\n",
    "\n",
    "# 운영체제와의 상호작용을 돕는 다양한 기능을 제공\n",
    "# 1. 현재 디렉토리 확인하기\n",
    "# 2. 디렉토리 변경\n",
    "# 3. 현재 디렉토리의 파일 목록 확인하기\n",
    "# 4. csv 파일 호출\n",
    "import os\n",
    "\n",
    "# 파이썬에서의 이미지 처리\n",
    "from PIL import Image\n",
    "\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "\n",
    "# 경고 메시지를 무시하고 숨기거나  -> warnings.filterwarnings(action='ignore')\n",
    "# 일치하는 경고를 인쇄하지 않습니다 = ('ignore')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 원하는 종류의 색깔만 넘겨주는 것\n",
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        #rmse = mean_squared_error(y, y_pred=sr)**0.5\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc = 오디오 신호에서 추출할 수 있는 feature로, 소리의 고유한 특징을 나타내는 수치\n",
    "#      = 등록된 음성과 현재 입력된 음성의 유사도를 판별하는 근거의 일부로 쓰입니다.\n",
    "#      = MFCC(Mel-Frequency Cepstral Coefficient)는\n",
    "#        Mel Spectrum(멜 스펙트럼)에서 Cepstral(켑스트럴) 분석을 통해 추출된 값\n",
    "#      \n",
    "# 이해하기 위해 먼저 \n",
    "# -  Spectrum(스펙트럼)\n",
    "# -  Cepstrum(켑스트럼)\n",
    "# -  Mel Spectrum(멜 스펙트럼)  들을 알아야 한다.\n",
    "# \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00023.wav</td>\n",
       "      <td>0.280714</td>\n",
       "      <td>0.102002</td>\n",
       "      <td>1210.197917</td>\n",
       "      <td>1497.822809</td>\n",
       "      <td>2522.101416</td>\n",
       "      <td>0.052483</td>\n",
       "      <td>-227.264786</td>\n",
       "      <td>137.762375</td>\n",
       "      <td>-14.500460</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.432815</td>\n",
       "      <td>-10.916914</td>\n",
       "      <td>3.569436</td>\n",
       "      <td>4.139583</td>\n",
       "      <td>0.092947</td>\n",
       "      <td>-2.972928</td>\n",
       "      <td>-1.376940</td>\n",
       "      <td>7.550498</td>\n",
       "      <td>-3.032519</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00062.wav</td>\n",
       "      <td>0.311780</td>\n",
       "      <td>0.106240</td>\n",
       "      <td>2279.895453</td>\n",
       "      <td>2119.726057</td>\n",
       "      <td>4732.338051</td>\n",
       "      <td>0.117149</td>\n",
       "      <td>-144.967926</td>\n",
       "      <td>95.726479</td>\n",
       "      <td>-21.598646</td>\n",
       "      <td>...</td>\n",
       "      <td>6.365178</td>\n",
       "      <td>-21.083876</td>\n",
       "      <td>2.452762</td>\n",
       "      <td>-9.533539</td>\n",
       "      <td>-1.422651</td>\n",
       "      <td>-9.327805</td>\n",
       "      <td>5.136750</td>\n",
       "      <td>-8.103219</td>\n",
       "      <td>-2.445028</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00074.wav</td>\n",
       "      <td>0.367157</td>\n",
       "      <td>0.196956</td>\n",
       "      <td>2515.864861</td>\n",
       "      <td>2531.449159</td>\n",
       "      <td>5771.631766</td>\n",
       "      <td>0.120916</td>\n",
       "      <td>-56.004456</td>\n",
       "      <td>87.837112</td>\n",
       "      <td>-1.598438</td>\n",
       "      <td>...</td>\n",
       "      <td>11.849050</td>\n",
       "      <td>-3.977553</td>\n",
       "      <td>7.098089</td>\n",
       "      <td>-4.465408</td>\n",
       "      <td>5.120333</td>\n",
       "      <td>-6.648911</td>\n",
       "      <td>5.869998</td>\n",
       "      <td>-3.696436</td>\n",
       "      <td>-1.965981</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00013.wav</td>\n",
       "      <td>0.264616</td>\n",
       "      <td>0.113221</td>\n",
       "      <td>1324.304356</td>\n",
       "      <td>1827.737535</td>\n",
       "      <td>2710.033613</td>\n",
       "      <td>0.051417</td>\n",
       "      <td>-209.789261</td>\n",
       "      <td>124.458443</td>\n",
       "      <td>10.310378</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205934</td>\n",
       "      <td>-3.038193</td>\n",
       "      <td>8.645517</td>\n",
       "      <td>-0.304231</td>\n",
       "      <td>-0.637742</td>\n",
       "      <td>-2.939885</td>\n",
       "      <td>-1.705922</td>\n",
       "      <td>-1.769590</td>\n",
       "      <td>-7.762958</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00066.wav</td>\n",
       "      <td>0.374710</td>\n",
       "      <td>0.110496</td>\n",
       "      <td>2340.432873</td>\n",
       "      <td>2256.538115</td>\n",
       "      <td>4972.503265</td>\n",
       "      <td>0.121775</td>\n",
       "      <td>-116.517403</td>\n",
       "      <td>97.430283</td>\n",
       "      <td>-13.880191</td>\n",
       "      <td>...</td>\n",
       "      <td>10.998191</td>\n",
       "      <td>-13.861800</td>\n",
       "      <td>9.735367</td>\n",
       "      <td>-5.089488</td>\n",
       "      <td>2.634638</td>\n",
       "      <td>-9.883816</td>\n",
       "      <td>6.159059</td>\n",
       "      <td>-7.682608</td>\n",
       "      <td>-4.852479</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00023.wav     0.280714  0.102002        1210.197917   \n",
       "1  blues.00062.wav     0.311780  0.106240        2279.895453   \n",
       "2  blues.00074.wav     0.367157  0.196956        2515.864861   \n",
       "3  blues.00013.wav     0.264616  0.113221        1324.304356   \n",
       "4  blues.00066.wav     0.374710  0.110496        2340.432873   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         1497.822809  2522.101416            0.052483 -227.264786   \n",
       "1         2119.726057  4732.338051            0.117149 -144.967926   \n",
       "2         2531.449159  5771.631766            0.120916  -56.004456   \n",
       "3         1827.737535  2710.033613            0.051417 -209.789261   \n",
       "4         2256.538115  4972.503265            0.121775 -116.517403   \n",
       "\n",
       "        mfcc2      mfcc3  ...     mfcc12     mfcc13    mfcc14    mfcc15  \\\n",
       "0  137.762375 -14.500460  ...  -9.432815 -10.916914  3.569436  4.139583   \n",
       "1   95.726479 -21.598646  ...   6.365178 -21.083876  2.452762 -9.533539   \n",
       "2   87.837112  -1.598438  ...  11.849050  -3.977553  7.098089 -4.465408   \n",
       "3  124.458443  10.310378  ...  -2.205934  -3.038193  8.645517 -0.304231   \n",
       "4   97.430283 -13.880191  ...  10.998191 -13.861800  9.735367 -5.089488   \n",
       "\n",
       "     mfcc16    mfcc17    mfcc18    mfcc19    mfcc20  label  \n",
       "0  0.092947 -2.972928 -1.376940  7.550498 -3.032519  blues  \n",
       "1 -1.422651 -9.327805  5.136750 -8.103219 -2.445028  blues  \n",
       "2  5.120333 -6.648911  5.869998 -3.696436 -1.965981  blues  \n",
       "3 -0.637742 -2.939885 -1.705922 -1.769590 -7.762958  blues  \n",
       "4  2.634638 -9.883816  6.159059 -7.682608 -4.852479  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()\n",
    "\n",
    "# chroma_stft = 채도_? , 크로마 표준\n",
    "# spectral_centroid = 스펙트럼 중심\n",
    "# spectral_bandwidth = 스펙트럼 대역폭\n",
    "# rolloff = 롤 오프\n",
    "# zero_crossing_rate = 제로 크로싱 비율\n",
    "#        \n",
    "# mfcc[n] = 오디오에서 추출한 여러개의 고유한(?) 소리들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49155625,  0.53504665,  0.15399013, -0.34545274, -0.02763979,\n",
       "        0.88369273,  1.02886264,  0.18682988, -1.6151689 ,  1.06895405,\n",
       "       -1.41321546,  0.75089536, -1.25578969,  1.00783983, -1.38388622,\n",
       "        1.22832268, -1.3429674 ,  1.01750756, -1.51728113,  0.20823112,\n",
       "       -1.15097788,  0.47702874, -0.93058682,  0.82380712, -0.35825568,\n",
       "        0.2428992 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 2.2231 - acc: 0.2075\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 12us/step - loss: 1.9582 - acc: 0.3387\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 14us/step - loss: 1.7345 - acc: 0.4037\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 13us/step - loss: 1.5269 - acc: 0.4550\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 17us/step - loss: 1.3593 - acc: 0.5337\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 14us/step - loss: 1.2273 - acc: 0.5700\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 17us/step - loss: 1.1287 - acc: 0.6250\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 15us/step - loss: 1.0345 - acc: 0.6737\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 15us/step - loss: 0.9699 - acc: 0.6962\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 16us/step - loss: 0.9091 - acc: 0.7137\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 17us/step - loss: 0.8531 - acc: 0.7300\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 14us/step - loss: 0.8046 - acc: 0.7450\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 14us/step - loss: 0.7624 - acc: 0.7612\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 14us/step - loss: 0.7222 - acc: 0.7712\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 16us/step - loss: 0.6961 - acc: 0.7775\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 15us/step - loss: 0.6799 - acc: 0.7800\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 14us/step - loss: 0.6328 - acc: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 12us/step - loss: 0.6014 - acc: 0.8188\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 12us/step - loss: 0.5729 - acc: 0.8200\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 13us/step - loss: 0.5423 - acc: 0.8212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 138us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:  0.65\n"
     ]
    }
   ],
   "source": [
    "print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = X_train[:200]\n",
    "partial_x_train = X_train[200:]\n",
    "\n",
    "y_val = y_train[:200]\n",
    "partial_y_train = y_train[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 200 samples\n",
      "Epoch 1/30\n",
      "600/600 [==============================] - 0s 344us/step - loss: 2.3290 - acc: 0.1150 - val_loss: 2.1734 - val_acc: 0.2650\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 2.1435 - acc: 0.2700 - val_loss: 2.0443 - val_acc: 0.3200\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 0s 15us/step - loss: 2.0080 - acc: 0.3450 - val_loss: 1.9423 - val_acc: 0.3400\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 0s 15us/step - loss: 1.8919 - acc: 0.3683 - val_loss: 1.8373 - val_acc: 0.3650\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 1.7751 - acc: 0.3850 - val_loss: 1.7312 - val_acc: 0.4000\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 0s 15us/step - loss: 1.6601 - acc: 0.4150 - val_loss: 1.6257 - val_acc: 0.4450\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 1.5518 - acc: 0.4483 - val_loss: 1.5228 - val_acc: 0.4800\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 1.4509 - acc: 0.5083 - val_loss: 1.4356 - val_acc: 0.5100\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 1.3636 - acc: 0.5117 - val_loss: 1.3681 - val_acc: 0.5500\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 1.2912 - acc: 0.5517 - val_loss: 1.3059 - val_acc: 0.5500\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 1.2183 - acc: 0.5817 - val_loss: 1.2340 - val_acc: 0.5850\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 1.1578 - acc: 0.6183 - val_loss: 1.1806 - val_acc: 0.6000\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 1.1225 - acc: 0.6283 - val_loss: 1.1283 - val_acc: 0.6550\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 1.0691 - acc: 0.6633 - val_loss: 1.1241 - val_acc: 0.6650\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 0s 16us/step - loss: 1.0430 - acc: 0.6800 - val_loss: 1.0970 - val_acc: 0.6700\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 0.9823 - acc: 0.6700 - val_loss: 1.0869 - val_acc: 0.6350\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 0s 15us/step - loss: 0.9670 - acc: 0.6750 - val_loss: 1.0746 - val_acc: 0.6200\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 0s 15us/step - loss: 0.9282 - acc: 0.6733 - val_loss: 1.0550 - val_acc: 0.6700\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 0.8775 - acc: 0.7133 - val_loss: 1.0837 - val_acc: 0.6450\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 0.8786 - acc: 0.7183 - val_loss: 1.0064 - val_acc: 0.6700\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 0.8140 - acc: 0.7517 - val_loss: 0.9650 - val_acc: 0.6950\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 0s 11us/step - loss: 0.7885 - acc: 0.7317 - val_loss: 0.9709 - val_acc: 0.7100\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 0s 16us/step - loss: 0.7682 - acc: 0.7400 - val_loss: 0.9831 - val_acc: 0.7000\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 0.7394 - acc: 0.7483 - val_loss: 0.9888 - val_acc: 0.7050\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 0.7148 - acc: 0.7750 - val_loss: 0.9632 - val_acc: 0.7150\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 0.6889 - acc: 0.7833 - val_loss: 0.9403 - val_acc: 0.7000\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 0.6523 - acc: 0.7817 - val_loss: 0.9429 - val_acc: 0.7100\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 0.6328 - acc: 0.7900 - val_loss: 0.9292 - val_acc: 0.7150\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 0.6108 - acc: 0.7950 - val_loss: 0.9026 - val_acc: 0.7450\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 0s 16us/step - loss: 0.5978 - acc: 0.8000 - val_loss: 0.9227 - val_acc: 0.6850\n",
      "200/200 [==============================] - 0s 23us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=30,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.183245961666107, 0.585]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
